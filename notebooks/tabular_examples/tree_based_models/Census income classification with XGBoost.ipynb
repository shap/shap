{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Census income classification with XGBoost\n",
    "\n",
    "This notebook demonstrates how to use XGBoost to predict the probability of an individual making over $50K a year in annual income. It uses the standard UCI Adult income dataset. To download a copy of this notebook visit [github](https://github.com/shap/shap/tree/master/notebooks).\n",
    "\n",
    "Gradient boosting machine methods such as XGBoost are state-of-the-art for these types of prediction problems with tabular style input data of many modalities. Tree SHAP ([arXiv paper](https://arxiv.org/abs/1802.03888)) allows for the exact computation of SHAP values for tree ensemble methods, and has been integrated directly into the C++ XGBoost code base. This allows fast exact computation of SHAP values without sampling and without providing a background dataset (since the background is inferred from the coverage of the trees).\n",
    "\n",
    "Here we demonstrate how to use SHAP values to understand XGBoost model predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost\n",
    "import shap\n",
    "import numpy as np\n",
    "import matplotlib.pylab as pl\n",
    "\n",
    "# print the JS visualization code to the notebook\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = shap.datasets.adult()\n",
    "X_display,y_display = shap.datasets.adult(display=True)\n",
    "\n",
    "# create a train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "d_train = xgboost.DMatrix(X_train, label=y_train)\n",
    "d_test = xgboost.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"eta\": 0.01,\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"subsample\": 0.5,\n",
    "    \"base_score\": np.mean(y_train),\n",
    "    \"eval_metric\": \"logloss\"\n",
    "}\n",
    "model = xgboost.train(params, d_train, 5000, evals = [(d_test, \"test\")], verbose_eval=100, early_stopping_rounds=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classic feature attributions\n",
    "\n",
    "Here we try out the global feature importance calcuations that come with XGBoost. Note that they all contradict each other, which motivates the use of SHAP values since they come with consistency gaurentees (meaning they will order the features correctly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost.plot_importance(model)\n",
    "pl.title(\"xgboost.plot_importance(model)\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost.plot_importance(model, importance_type=\"cover\")\n",
    "pl.title('xgboost.plot_importance(model, importance_type=\"cover\")')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost.plot_importance(model, importance_type=\"gain\")\n",
    "pl.title('xgboost.plot_importance(model, importance_type=\"gain\")')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain predictions\n",
    "\n",
    "Here we use the Tree SHAP implementation integrated into XGBoost to explain the entire dataset (32561 samples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this takes a minute or two since we are explaining over 30 thousand samples in a model with over a thousand trees\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize a single prediction\n",
    "\n",
    "Note that we use the \"display values\" data frame so we get nice strings instead of category codes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value, shap_values[0,:], X_display.iloc[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize many predictions\n",
    "\n",
    "To keep the browser happy we only visualize 1,000 individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value, shap_values[:1000,:], X_display.iloc[:1000,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bar chart of mean importance\n",
    "\n",
    "This takes the average of the SHAP value magnitudes across the dataset and plots it as a simple bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_display, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP Summary Plot\n",
    "\n",
    "Rather than use a typical feature importance bar chart, we use a density scatter plot of SHAP values for each feature to identify how much impact each feature has on the model output for individuals in the validation dataset. Features are sorted by the sum of the SHAP value magnitudes across all samples. It is interesting to note that the relationship feature has more total model impact than the captial gain feature, but for those samples where capital gain matters it has more impact than age. In other words, capital gain effects a few predictions by a large amount, while age effects all predictions by a smaller amount.\n",
    "\n",
    "Note that when the scatter points don't fit on a line they pile up to show density, and the color of each point represents the feature value of that individual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP Dependence Plots\n",
    "\n",
    "SHAP dependence plots show the effect of a single feature across the whole dataset. They plot a feature's value vs. the SHAP value of that feature across many samples. SHAP dependence plots are similar to partial dependence plots, but account for the interaction effects present in the features, and are only defined in regions of the input space supported by data. The vertical dispersion of SHAP values at a single feature value is driven by interaction effects, and another feature is chosen for coloring to highlight possible interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in X_train.columns:\n",
    "    shap.dependence_plot(name, shap_values, X, display_features=X_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple supervised clustering\n",
    "\n",
    "Clustering people by their shap_values leads to groups relevent to the prediction task at hand (their earning potential in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "shap_pca50 = PCA(n_components=12).fit_transform(shap_values[:1000,:])\n",
    "shap_embedded = TSNE(n_components=2, perplexity=50).fit_transform(shap_values[:1000,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "cdict1 = {\n",
    "    'red': ((0.0, 0.11764705882352941, 0.11764705882352941),\n",
    "            (1.0, 0.9607843137254902, 0.9607843137254902)),\n",
    "\n",
    "    'green': ((0.0, 0.5333333333333333, 0.5333333333333333),\n",
    "              (1.0, 0.15294117647058825, 0.15294117647058825)),\n",
    "\n",
    "    'blue': ((0.0, 0.8980392156862745, 0.8980392156862745),\n",
    "             (1.0, 0.3411764705882353, 0.3411764705882353)),\n",
    "\n",
    "    'alpha': ((0.0, 1, 1),\n",
    "              (0.5, 1, 1),\n",
    "              (1.0, 1, 1))\n",
    "}  # #1E88E5 -> #ff0052\n",
    "red_blue_solid = LinearSegmentedColormap('RedBlue', cdict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pl.figure(figsize=(5,5))\n",
    "pl.scatter(shap_embedded[:,0],\n",
    "           shap_embedded[:,1],\n",
    "           c=shap_values[:1000,:].sum(1).astype(np.float64),\n",
    "           linewidth=0, alpha=1., cmap=red_blue_solid)\n",
    "cb = pl.colorbar(label=\"Log odds of making > $50K\", aspect=40, orientation=\"horizontal\")\n",
    "cb.set_alpha(1)\n",
    "cb.draw_all()\n",
    "cb.outline.set_linewidth(0)\n",
    "cb.ax.tick_params('x', length=0)\n",
    "cb.ax.xaxis.set_label_position('top')\n",
    "pl.gca().axis(\"off\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in [\"Relationship\", \"Capital Gain\", \"Capital Loss\"]:\n",
    "    f = pl.figure(figsize=(5,5))\n",
    "    pl.scatter(shap_embedded[:,0],\n",
    "               shap_embedded[:,1],\n",
    "               c=X[feature].values[:1000].astype(np.float64),\n",
    "               linewidth=0, alpha=1., cmap=red_blue_solid)\n",
    "    cb = pl.colorbar(label=feature, aspect=40, orientation=\"horizontal\")\n",
    "    cb.set_alpha(1)\n",
    "    cb.draw_all()\n",
    "    cb.outline.set_linewidth(0)\n",
    "    cb.ax.tick_params('x', length=0)\n",
    "    cb.ax.xaxis.set_label_position('top')\n",
    "    pl.gca().axis(\"off\")\n",
    "    pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model with only two leaves per tree and hence no interaction terms between features\n",
    "\n",
    "Forcing the model to have no interaction terms means the effect of a feature on the outcome does not depend on the value of any other feature. This is reflected in the SHAP dependence plots below as no vertical spread. A vertical spread reflects that a single value of a feature can have different effects on the model output depending on the context of the other features present for an individual. However, for models without interaction terms, a feature always has the same impact regardless of what other attributes an individual may have.\n",
    "\n",
    "One the benefits of SHAP dependence plots over traditional partial dependence plots is this ability to distigush between between models with and without interaction terms. In other words, SHAP dependence plots give an idea of the magnitude of the interaction terms through the vertical variance of the scatter plot at a given feature value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train final model on the full data set\n",
    "params = {\n",
    "    \"eta\": 0.05,\n",
    "    \"max_depth\": 1,\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"subsample\": 0.5,\n",
    "    \"base_score\": np.mean(y_train),\n",
    "    \"eval_metric\": \"logloss\"\n",
    "}\n",
    "model_ind = xgboost.train(params, d_train, 5000, evals = [(d_test, \"test\")], verbose_eval=100, early_stopping_rounds=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_ind = shap.TreeExplainer(model_ind).shap_values(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the interaction color bars below are meaningless for this model because it has no interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in X_train.columns:\n",
    "    shap.dependence_plot(name, shap_values_ind, X, display_features=X_display)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
